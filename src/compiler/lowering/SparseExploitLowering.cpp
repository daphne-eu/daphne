/*
 * Copyright 2023 The DAPHNE Consortium
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include <memory>
#include <string>
#include <utility>

#include <compiler/utils/CompilerUtils.h>
#include <compiler/utils/LoweringUtils.h>
#include <util/ErrorHandler.h>

#include "ir/daphneir/Daphne.h"
#include "ir/daphneir/Passes.h"
#include "mlir/Conversion/ArithToLLVM/ArithToLLVM.h"
#include "mlir/Conversion/LLVMCommon/LoweringOptions.h"
#include "mlir/Conversion/LLVMCommon/TypeConverter.h"
#include "mlir/Dialect/Affine/IR/AffineOps.h"
#include "mlir/Dialect/Arith/IR/Arith.h"
#include "mlir/Dialect/LLVMIR/LLVMDialect.h"
#include "mlir/Dialect/Math/IR/Math.h"
#include "mlir/Dialect/MemRef/IR/MemRef.h"
#include "mlir/Dialect/SCF/IR/SCF.h"
#include "mlir/IR/AffineExpr.h"
#include "mlir/IR/Builders.h"
#include "mlir/IR/BuiltinDialect.h"
#include "mlir/IR/BuiltinTypeInterfaces.h"
#include "mlir/IR/BuiltinTypes.h"
#include "mlir/IR/DialectInterface.h"
#include "mlir/IR/Location.h"
#include "mlir/IR/PatternMatch.h"
#include "mlir/IR/TypeRange.h"
#include "mlir/IR/TypeUtilities.h"
#include "mlir/IR/Value.h"
#include "mlir/IR/ValueRange.h"
#include "mlir/Pass/Pass.h"
#include "mlir/Support/LLVM.h"
#include "mlir/Support/LogicalResult.h"
#include "mlir/Transforms/DialectConversion.h"
#include "llvm/ADT/ArrayRef.h"

using namespace mlir;

/**
 * @brief sum(sparse * ln(dense @ dense)) where either dense matrix can be transposed
 */
class SparseExploitLowering final : public mlir::OpConversionPattern<daphne::AllAggSumOp> {
  public:
    using OpConversionPattern::OpAdaptor;

    SparseExploitLowering(TypeConverter &typeConverter, mlir::MLIRContext *ctx)
        : mlir::OpConversionPattern<daphne::AllAggSumOp>(typeConverter, ctx) {
        this->setDebugName("SparseExploitLowering");
    }

    LogicalResult matchAndRewrite(daphne::AllAggSumOp op, OpAdaptor adaptor,
                                  ConversionPatternRewriter &rewriter) const override {
        Location loc = op->getLoc();

        // ------------------------------------------------------------------------------------
        // Pattern Matching     allAgg( IntersectOp( sparseLhs, ln(denseLhs @ denseRhs) ) )
        // ------------------------------------------------------------------------------------

        // Rewrite is only called after the pattern has already been matched during legalization, so the results are
        // assumed not to be nullptr.
        Operation *sparseIntersectOp =
            adaptor.getArg().getDefiningOp(); // IntersectOp( sparseLhs, ln(denseLhs @ denseRhs) )

        Value sparseLhs = sparseIntersectOp->getOperand(0);
        Operation *unaryOp = sparseIntersectOp->getOperand(1).getDefiningOp(); // ln(denseLhs @ denseRhs)

        Operation *denseMatmulOp = unaryOp->getOperand(0).getDefiningOp(); // denseLhs @ denseRhs

        // daphne.matMul Op has 4 arguments, the latter two (`transa`, `transb`) are bools indicating whether
        // either matrix should be accessed as though it was transposed.
        Value denseLhs = denseMatmulOp->getOperand(0);
        Value denseRhs = denseMatmulOp->getOperand(1);
        bool transa = CompilerUtils::constantOrThrow<bool>(
            denseMatmulOp->getOperand(2), "SparseExploitLowering: expected transa to be known at compile-time");
        bool transb = CompilerUtils::constantOrThrow<bool>(
            denseMatmulOp->getOperand(3), "SparseExploitLowering: expected transb to be known at compile-time");

        auto sparseLhsMatType = sparseLhs.getType().template dyn_cast<daphne::MatrixType>();
        Type resElementType = sparseLhsMatType.getElementType();
        ssize_t sparseLhsRows = sparseLhsMatType.getNumRows();
        ssize_t sparseLhsCols = sparseLhsMatType.getNumCols();

        auto denseLhsMatType = denseLhs.getType().template dyn_cast<daphne::MatrixType>();
        Type dotProdElementType = sparseLhsMatType.getElementType();
        ssize_t denseLhsRows = denseLhsMatType.getNumRows();
        ssize_t denseLhsCols = denseLhsMatType.getNumCols();

        auto denseRhsMatType = denseRhs.getType().template dyn_cast<daphne::MatrixType>();
        ssize_t denseRhsRows = denseRhsMatType.getNumRows();
        ssize_t denseRhsCols = denseRhsMatType.getNumCols();

        if (sparseLhsRows < 0 || sparseLhsCols < 0 || denseLhsRows < 0 || denseLhsCols < 0 || denseRhsRows < 0 ||
            denseRhsCols < 0) {
            return rewriter.notifyMatchFailure(
                op,
                "sparse exploit codegen currently only works with matrix dimensions that are known at compile time");
        }

        // Verify dense-dense Matmul and sparse-dense intersection op have matching dimensions.
        if ((transa ? denseLhsRows : denseLhsCols) != (transb ? denseRhsCols : denseRhsRows)) {
            throw ErrorHandler::compilerError(
                loc, "SparseExploitLowering",
                "dense-dense matrix multiplication operands must have matching inner dimension (given: "
                "(" +
                    std::to_string(transa ? denseLhsCols : denseLhsRows) + "x" +
                    std::to_string(transa ? denseLhsRows : denseLhsCols) + ") and (" +
                    std::to_string(transb ? denseRhsCols : denseRhsRows) + "x" +
                    std::to_string(transb ? denseRhsRows : denseRhsCols) + ")");
        }
        if (sparseLhsRows != (transa ? denseLhsCols : denseLhsRows) ||
            sparseLhsCols != (transb ? denseRhsRows : denseRhsCols)) {
            throw ErrorHandler::compilerError(
                loc, "SparseExploitLowering",
                "sparse-dense intersectionOp operands must have equal dimensions (given: (" +
                    std::to_string(sparseLhsRows) + "x" + std::to_string(sparseLhsCols) + ") and (" +
                    std::to_string(transa ? denseLhsCols : denseLhsRows) + "x" +
                    std::to_string(transb ? denseRhsRows : denseRhsCols) + ")");
        }

        MemRefType denseLhsMemRefType = MemRefType::get({denseLhsRows, denseLhsCols}, denseLhsMatType.getElementType());
        MemRefType denseRhsMemRefType = MemRefType::get({denseRhsRows, denseRhsCols}, denseRhsMatType.getElementType());
        auto denseLhsMemRef = rewriter.create<daphne::ConvertDenseMatrixToMemRef>(loc, denseLhsMemRefType, denseLhs);
        auto denseRhsMemRef = rewriter.create<daphne::ConvertDenseMatrixToMemRef>(loc, denseRhsMemRefType, denseRhs);

        MemRefType sparseLhsValuesMemRefType =
            MemRefType::get({ShapedType::kDynamic}, sparseLhsMatType.getElementType());
        MemRefType sparseLhsColIdxsMemRefType = MemRefType::get({ShapedType::kDynamic}, rewriter.getIndexType());
        MemRefType sparseLhsRowOffsetsMemRefType = MemRefType::get({sparseLhsRows + 1}, rewriter.getIndexType());

        auto argValues =
            rewriter.create<daphne::ConvertCSRMatrixToValuesMemRef>(loc, sparseLhsValuesMemRefType, sparseLhs);
        auto argColIdx =
            rewriter.create<daphne::ConvertCSRMatrixToColIdxsMemRef>(loc, sparseLhsColIdxsMemRefType, sparseLhs);
        auto argRowPtr =
            rewriter.create<daphne::ConvertCSRMatrixToRowOffsetsMemRef>(loc, sparseLhsRowOffsetsMemRefType, sparseLhs);

        /* The loop nest below loops first over the row offsets, meaning over the rows of the CSRMatrix.
         *
         * Then, in a nested loop, over it iterates over the range created by the difference of an entry in
         * row offsets and its successor, which corresponds to the column length of row the first offset was taken of.
         *
         * Finally, the inner-most loop simply computes the dot product of the dense matrices at the given
         * row/column indices. Its result is passed to the first nested loop that computes the logarithm,
         * multiplies it with the value at the same indices in the CSRMatrix, and passes it to the outer
         * loop which performs a (thread safe) addition.
         *
         * Todo: Test parallelization of the two inner scf loops (replace with scf::parallel / scf::reduce instead of
         * scf::yield) and enable lowering of parallel loops to different threads (e.g. using omp dialect/OpenMP
         * library).
         */
        auto outerLoop = rewriter.create<AffineParallelOp>(loc, TypeRange{resElementType},
                                                           ArrayRef<arith::AtomicRMWKind>{arith::AtomicRMWKind::addf},
                                                           ArrayRef<ssize_t>{sparseLhsRows});
        rewriter.setInsertionPointToStart(outerLoop.getBody());
        {
            Value rowPtr = rewriter.create<AffineLoadOp>(loc, argRowPtr, ValueRange{outerLoop.getIVs()[0]});
            Value nextRowPtr = rewriter.create<AffineLoadOp>(
                loc, argRowPtr, AffineMap::get(1, 0, rewriter.getAffineDimExpr(0) + 1, rewriter.getContext()),
                ValueRange{outerLoop.getIVs()[0]});

            Value innerLoopAcc = rewriter.create<arith::ConstantOp>(loc, rewriter.getZeroAttr(resElementType));

            auto innerLoop = rewriter.create<scf::ForOp>(
                loc, rowPtr, nextRowPtr, rewriter.create<arith::ConstantIndexOp>(loc, 1), ValueRange{innerLoopAcc},
                [&](OpBuilder &OpBuilderNested, Location locNested, Value loopIdx, ValueRange loopInvariants) {
                    Value colIdx = OpBuilderNested.create<memref::LoadOp>(locNested, argColIdx, ValueRange{loopIdx});

                    Value resDotProd = OpBuilderNested.create<arith::ConstantOp>(
                        locNested, OpBuilderNested.getZeroAttr(dotProdElementType));

                    auto dotProdLoop = OpBuilderNested.create<scf::ForOp>(
                        locNested, rewriter.create<arith::ConstantIndexOp>(loc, 0),
                        rewriter.create<arith::ConstantIndexOp>(loc, denseLhsCols),
                        rewriter.create<arith::ConstantIndexOp>(loc, 1), ValueRange{resDotProd},
                        [&](OpBuilder &OpBuilderTwiceNested, Location locTwiceNested, Value loopIdxNested,
                            ValueRange loopInvariantsNested) {
                            Value currentValLhs = OpBuilderTwiceNested.create<memref::LoadOp>(
                                locTwiceNested, denseLhsMemRef,
                                transa ? ValueRange{loopIdxNested, outerLoop.getIVs()[0]}
                                       : ValueRange{outerLoop.getIVs()[0], loopIdxNested});
                            Value currentValRhs = OpBuilderTwiceNested.create<memref::LoadOp>(
                                locTwiceNested, denseRhsMemRef,
                                transb ? ValueRange{colIdx, loopIdxNested} : ValueRange{loopIdxNested, colIdx});

                            Value accDotProd;
                            if (llvm::isa<IntegerType>(dotProdElementType)) {
                                currentValLhs = convertToSignlessInt(OpBuilderTwiceNested, locTwiceNested,
                                                                     typeConverter, currentValLhs, dotProdElementType);
                                currentValRhs = convertToSignlessInt(OpBuilderTwiceNested, locTwiceNested,
                                                                     typeConverter, currentValRhs, dotProdElementType);
                                accDotProd = OpBuilderTwiceNested.create<arith::MulIOp>(locTwiceNested, currentValLhs,
                                                                                        currentValRhs);
                                accDotProd = OpBuilderTwiceNested.create<arith::AddIOp>(locTwiceNested, accDotProd,
                                                                                        loopInvariantsNested[0]);
                            } else {
                                accDotProd = OpBuilderTwiceNested.create<math::FmaOp>(
                                    locTwiceNested, currentValLhs, currentValRhs, loopInvariantsNested[0]);
                            }

                            OpBuilderTwiceNested.create<scf::YieldOp>(locTwiceNested, ValueRange{accDotProd});
                        }); // end dot product

                    Value dotProdLoopRes = dotProdLoop.getResult(0);
                    if (llvm::isa<IntegerType>(dotProdElementType)) {
                        dotProdLoopRes = this->typeConverter->materializeTargetConversion(
                            OpBuilderNested, locNested, resElementType, dotProdLoopRes);
                    }
                    Value mappedDotProd = OpBuilderNested.create<math::LogOp>(locNested, dotProdLoopRes);

                    Value currentVal =
                        OpBuilderNested.create<memref::LoadOp>(locNested, argValues, ValueRange{loopIdx});

                    // After log has been applied, arg will always be a float type so FMA is no restriction
                    Value intersectAggRes =
                        OpBuilderNested.create<math::FmaOp>(locNested, currentVal, mappedDotProd, loopInvariants[0]);

                    OpBuilderNested.create<scf::YieldOp>(locNested, ValueRange{intersectAggRes});
                }); // end inner loop

            rewriter.create<AffineYieldOp>(loc, ValueRange{innerLoop.getResult(0)});
        } // end outer loop
        rewriter.setInsertionPointAfter(outerLoop);

        rewriter.replaceOp(op, outerLoop->getResult(0));
        return success();
    }
};

// ****************************************************************************
// General Pass Setup
// ****************************************************************************

namespace {
/**
 * @brief This pass lowers a specific pattern of sparse-dense operations
 * to a loop nest that avoids materializing potentially large dense intermediates.
 *
 * The matched pattern is sum(sparse * ln(dense @ dense))
 * where either dense matrix can be transposed.
 */
struct SparseExploitLoweringPass
    : public mlir::PassWrapper<SparseExploitLoweringPass, mlir::OperationPass<mlir::ModuleOp>> {
    explicit SparseExploitLoweringPass() = default;

    void getDependentDialects(mlir::DialectRegistry &registry) const override {
        registry.insert<mlir::AffineDialect, mlir::arith::ArithDialect, daphne::DaphneDialect, mlir::LLVM::LLVMDialect,
                        mlir::math::MathDialect, memref::MemRefDialect, scf::SCFDialect>();
    }
    void runOnOperation() final;

    [[nodiscard]] StringRef getArgument() const final { return "lower-sparse-exploit"; }
    [[nodiscard]] StringRef getDescription() const final {
        return "This pass lowers a sum(sparse * ln(dense @ dense)) pattern "
               "to 3 nested loops that avoid materializing potentially large dense intermediates.";
    }
};
} // end anonymous namespace

void SparseExploitLoweringPass::runOnOperation() {
    mlir::ConversionTarget target(getContext());
    mlir::RewritePatternSet patterns(&getContext());
    mlir::LowerToLLVMOptions llvmOptions(&getContext());
    mlir::LLVMTypeConverter typeConverter(&getContext(), llvmOptions);

    typeConverter.addConversion(convertInteger);
    typeConverter.addConversion(convertFloat);
    typeConverter.addConversion([](Type type) { return type; });
    typeConverter.addArgumentMaterialization(materializeCastFromIllegal);
    typeConverter.addSourceMaterialization(materializeCastToIllegal);
    typeConverter.addTargetMaterialization(materializeCastFromIllegal);

    target.addLegalDialect<mlir::AffineDialect, mlir::arith::ArithDialect, mlir::BuiltinDialect, daphne::DaphneDialect,
                           mlir::LLVM::LLVMDialect, mlir::math::MathDialect, memref::MemRefDialect, scf::SCFDialect>();

    // Marks Op as illegal only if it matches the pattern:  sum(sparse * ln(dense @ dense))
    target.addDynamicallyLegalOp<daphne::AllAggSumOp>([](Operation *op) {
        Operation *definingEwMulOp = op->getOperand(0).getDefiningOp<daphne::EwMulOp>();
        if (definingEwMulOp == nullptr) {
            return true;
        }

        Type lhsType = definingEwMulOp->getOperand(0).getType();
        auto lhsMatType = lhsType.dyn_cast<daphne::MatrixType>();

        Value rhs = definingEwMulOp->getOperand(1);
        Type rhsType = rhs.getType();
        auto rhsMatType = rhsType.dyn_cast<daphne::MatrixType>();

        if (!lhsMatType || !rhsMatType) {
            return true;
        }
        if (lhsMatType.getRepresentation() != daphne::MatrixRepresentation::Sparse ||
            rhsMatType.getRepresentation() != daphne::MatrixRepresentation::Dense) {
            return true;
        }

        Operation *definingEwLnOp = rhs.getDefiningOp<daphne::EwLnOp>();
        if (definingEwLnOp == nullptr) {
            return true;
        }

        Operation *definingMatMulOp = definingEwLnOp->getOperand(0).getDefiningOp<daphne::MatMulOp>();
        if (definingMatMulOp == nullptr) {
            return true;
        }

        Type matmulLhsType = definingMatMulOp->getOperand(0).getType();
        Type matmulRhsType = definingMatMulOp->getOperand(1).getType();
        auto matmulLhsMatType = matmulLhsType.dyn_cast<daphne::MatrixType>();
        auto matmulRhsMatType = matmulRhsType.dyn_cast<daphne::MatrixType>();

        if (matmulLhsMatType.getRepresentation() != daphne::MatrixRepresentation::Dense ||
            matmulRhsMatType.getRepresentation() != daphne::MatrixRepresentation::Dense) {
            return true;
        }

        return false;
    });

    patterns.insert<SparseExploitLowering>(typeConverter, &getContext());
    auto module = getOperation();
    if (failed(applyPartialConversion(module, target, std::move(patterns))))
        signalPassFailure();
}

std::unique_ptr<mlir::Pass> daphne::createSparseExploitLoweringPass() {
    return std::make_unique<SparseExploitLoweringPass>();
}
