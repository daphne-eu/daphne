import os
import time
import subprocess
import numpy as np
import json

# Set paths
dml_file = os.path.abspath("../../../thirdparty/systemds/scripts/builtin/shortestPath.dml")
dml_file_caller = os.path.abspath("shortestPath_.dml")#../../../thirdparty/systemds/src/test/scripts/functions/builtin/shortestPathTest.dml")

translator_file = os.path.abspath("../../dml2daph.py")
daph_file = os.path.abspath("../../translated_files/shortestPath.daph")   # is generated by translator
daph_file_caller = os.path.abspath("shortestPath_.daph")

# Generate data
maxi = 0
sourceNode = 1

test_matrix = np.random.randint(0, 2001, size=(4000, 4000))
np.fill_diagonal(test_matrix, 0)

os.makedirs(os.path.abspath("data"), exist_ok=True)
test_matrix_file_dml = os.path.abspath("data/test_matrix_dml.csv")
test_matrix_file_daph = os.path.abspath("data/test_matrix_daph.csv")

# Save the matrix to a file
np.savetxt(test_matrix_file_dml, test_matrix, delimiter=',')
np.savetxt(test_matrix_file_daph, test_matrix, delimiter=',')

# Create metadata for the test matrix
test_matrix_metadata_dml = {
    "data_type": "matrix",
    "format": "csv",
    "rows": test_matrix.shape[0],
    "cols": test_matrix.shape[1]
}

test_matrix_metadata_daph = {
    "numRows": test_matrix.shape[0],
    "numCols": test_matrix.shape[1],
    "valueType": "f64",
    "numNonZeros": 0
}

# Save metadata to a file
with open(test_matrix_file_dml + ".mtd", 'w') as f:
    json.dump(test_matrix_metadata_dml, f)

with open(test_matrix_file_daph + ".meta", 'w') as f:
    json.dump(test_matrix_metadata_daph, f)

# Run the DML script
dml_output_file = os.path.abspath("output/dml_output.csv")
dml_command = "cd ../../../thirdparty/systemds/target && spark-submit SystemDS.jar -f {} -args {}".format(dml_file_caller, test_matrix_file_dml)

start_time_dml = time.time()
subprocess.call(dml_command, shell=True)
end_time_dml = time.time()

# Load DML results
dml_results = np.loadtxt(dml_output_file, delimiter=' ')

# Translate DML to Daphne
translate_command = "python3 {} {}".format(translator_file, dml_file)
start_time_translator = time.time()
subprocess.call(translate_command, shell=True)
end_time_translator = time.time()

# Run the Daphne script
daphne_output_file = os.path.abspath("output/daphne_output.csv")
daphne_command = "../../../bin/daphne --timing {} maxi={} sourceNode={} verbose=false".format(daph_file_caller, maxi, sourceNode)

print("Information about executing time for daphne script:")
start_time_daphne = time.time()
subprocess.call(daphne_command, shell=True)
end_time_daphne = time.time()

# Load Daphne results
daphne_results = np.loadtxt(daphne_output_file, delimiter=',')

# Compare results
print("\nComparison for m_shortestPath: {}".format(np.allclose(dml_results[:,2], daphne_results[1:], atol=1e-08)))

dml_time = end_time_dml - start_time_dml
daph_time = end_time_daphne - start_time_daphne
translator_time = end_time_translator - start_time_translator

print("\nTime for running dml script: {}\nTime for running daphne script: {}\nTime for running translator: {}".format(dml_time, daph_time, translator_time))

