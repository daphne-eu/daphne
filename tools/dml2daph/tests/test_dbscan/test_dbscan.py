import os
import subprocess
import numpy as np
import json

# Set paths
dml_file = os.path.abspath("../../../thirdparty/systemds/scripts/builtin/dbscan.dml")
dml_file_caller = os.path.abspath("dbscan_.dml")

translator_file = os.path.abspath("../../dml2daph.py")
daph_file = os.path.abspath("../../translated_files/dbscan.daph")   # is generated by translator
daph_file_caller = os.path.abspath("dbscan_.daph")

# Generate data
eps = 0.5
minPts = 5
np.random.seed(0)

points_cluster_1 = np.random.normal(loc=0, scale=0.2, size=(8, 2))
points_cluster_2 = np.random.normal(loc=5, scale=0.2, size=(2, 2))
test_matrix = np.vstack((points_cluster_1, points_cluster_2))

os.makedirs(os.path.abspath("data"), exist_ok=True)
test_matrix_file_dml = os.path.abspath('data/test_matrix_dml.csv')
test_matrix_file_daph = os.path.abspath('data/test_matrix_daph.csv')

# Save the matrix to a file
np.savetxt(test_matrix_file_dml, test_matrix, delimiter=',')
np.savetxt(test_matrix_file_daph, test_matrix, delimiter=',')

# Create metadata for the test matrix
test_matrix_metadata_dml = {
    "data_type": "matrix",
    "format": "csv",
    "rows": test_matrix.shape[0],
    "cols": test_matrix.shape[1]
}

test_matrix_metadata_daph = {
    "numRows": test_matrix.shape[0],
    "numCols": test_matrix.shape[1],
    "valueType": "f64",
    "numNonZeros": 0
}

# Save metadata to a file
with open(test_matrix_file_dml + ".mtd", 'w') as f:
    json.dump(test_matrix_metadata_dml, f)

with open(test_matrix_file_daph + ".meta", 'w') as f:
    json.dump(test_matrix_metadata_daph, f)

# Run the DML script
dml_output_file = os.path.abspath('output/dml_output.csv')
dml_output_file2 = os.path.abspath('output/dml_output2.csv')
dml_command = "cd ../../../thirdparty/systemds/target && spark-submit SystemDS.jar -f {} -args {} {} {}".format(dml_file_caller, test_matrix_file_dml, eps, minPts)
subprocess.call(dml_command, shell=True)

# Load DML results
dml_results = np.loadtxt(dml_output_file, delimiter=' ')
dml_results2 = np.loadtxt(dml_output_file2, delimiter=' ')

# Translate DML to Daphne
translate_command = "python3 {} {}".format(translator_file, dml_file)
subprocess.call(translate_command, shell=True)

# Run the Daphne script
daphne_output_file = os.path.abspath('output/daphne_output.csv')
daphne_output_file2 = os.path.abspath('output/daphne_output2.csv')
daphne_command = "../../../bin/daphne {} eps={} minPts={}".format(daph_file_caller, eps, minPts)
subprocess.call(daphne_command, shell=True)

# Load Daphne results
daphne_results = np.loadtxt(daphne_output_file, delimiter=',')
daphne_results2 = np.loadtxt(daphne_output_file2, delimiter=',')

# Compare results (Dml's write() doesnt save trailing zeros but daphne's write() does, therefore the results have to be reshaped)
print("Comparison for m_dbscan: {}".format(np.allclose(dml_results[:,2], daphne_results.flatten()[:len(dml_results)], atol=1e-02) and np.allclose(dml_results2[:,2], daphne_results2.flatten(), atol=1e-02)))
