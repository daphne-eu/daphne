#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
# Modifications Copyright 2024 The DAPHNE Consortium
#
#-------------------------------------------------------------

# This script has been manually translated from Apache SystemDS.

/*
 * 2D Convolutional layer.
 *
 * This implementation uses a built-in operator for higher performance.
 */

import "../util.daph" as "util";

def forward(X:matrix, W:matrix, b:matrix, C, Hin, Win, Hf, Wf, strideh, stridew, padh, padw) -> matrix<f64>, si64, si64 {
  /*
   * Computes the forward pass for a 2D spatial convolutional layer with
   * F filters.  The input data has N examples, each represented as a 3D
   * volume unrolled into a single vector.
   *
   * This implementation uses a built-in operator for higher
   * performance.
   *
   * Inputs:
   *  - X: Inputs, of shape (N, C*Hin*Win).
   *  - W: Weights, of shape (F, C*Hf*Wf).
   *  - b: Biases, of shape (F, 1).
   *  - C: Number of input channels (dimensionality of depth).
   *  - Hin: Input height.
   *  - Win: Input width.
   *  - Hf: Filter height.
   *  - Wf: Filter width.
   *  - strideh: Stride over height.
   *  - stridew: Stride over width.
   *  - padh: Padding for top and bottom sides.
   *      For same output height as input, set `padh = (Hf - 1) / 2`,
   *      assuming `strideh = 1`.
   *      More generally, `padh = (Hin*(strideh-1) + Hf - strideh) / 2`
   *      preserves the spatial dimensions of the input.
   *  - padw: Padding for left and right sides.
   *      For same output width as input, set `padw = (Wf - 1) / 2`,
   *      assuming `stridew = 1`.
   *      More generally, `padw = (Win*(stridew-1) + Wf - stridew) / 2`
   *      preserves the spatial dimensions of the input.
   *
   * Outputs:
   *  - out: Outputs, of shape (N, F*Hout*Wout).
   *  - Hout: Output height.
   *  - Wout: Output width.
   */
  N = nrow(X);
  F = nrow(W);
  Hout = floor((Hin + 2*padh - Hf)/strideh + 1);
  Wout = floor((Win + 2*padw - Wf)/stridew + 1);

  # Convolution - built-in implementation
  #out = conv2d(X, W, input_shape=[N,C,Hin,Win], filter_shape=[F,C,Hf,Wf], stride=[strideh,stridew], padding=[padh,padw]);
  #out, Hout, Wout = conv2d(X, W, N, C, Hin, Win, Hf, Wf, strideh, stridew, padh, padw, b);
    out = fill(0.0, N, F * Hout * Wout);

print("conv2d: Hout: ",0,0); print(Hout);
print("conv2d: Wout: ",0,0); print(Wout);
  # Add bias term to each output filter
  #done within conv2d
  #out = biasAdd(out, b);
  return out, as.si64(Hout), as.si64(Wout);
  #return out, Hout, Wout;
}


def backward(dout:matrix, Hout, Wout, X:matrix, W:matrix, b:matrix, C, Hin, Win, Hf, Wf, strideh, stridew, padh, padw)
        -> matrix, matrix, matrix {
  /*
   * Computes the backward pass for a 2D spatial convolutional layer
   * with F filters.
   *
   * Inputs:
   *  - dout: Gradient wrt `out` from upstream, of
   *      shape (N, F*Hout*Wout).
   *  - Hout: Output height.
   *  - Wout: Output width.
   *  - X: Inputs, of shape (N, C*Hin*Win).
   *  - W: Weights, of shape (F, C*Hf*Wf).
   *  - b: Biases, of shape (F, 1).
   *  - C: Number of input channels (dimensionality of depth).
   *  - Hin: Input height.
   *  - Win: Input width.
   *  - Hf: Filter height.
   *  - Wf: Filter width.
   *  - strideh: Stride over height.
   *  - stridew: Stride over width.
   *  - padh: Padding for top and bottom sides.
   *      For same output height as input, set `padh = (Hf - 1) / 2`,
   *      assuming `strideh = 1`.
   *      More generally, `padh = (Hin*(strideh-1) + Hf - strideh) / 2`
   *      preserves the spatial dimensions of the input.
   *  - padw: Padding for left and right sides.
   *      For same output width as input, set `padw = (Wf - 1) / 2`,
   *      assuming `stridew = 1`.
   *      More generally, `padw = (Win*(stridew-1) + Wf - stridew) / 2`
   *      preserves the spatial dimensions of the input.
   *
   * Outputs:
   *  - dX: Gradient wrt `X`, of shape (N, C*Hin*Win).
   *  - dW: Gradient wrt `W`, of shape (F, C*Hf*Wf).
   *  - db: Gradient wrt `b`, of shape (F, 1).
   */
  N = nrow(X);
  F = nrow(W);

  #ToDo:
  # Partial derivatives for convolution - built-in implementation
#  dW = conv2d_backward_filter(X, dout, stride=[strideh,stridew], padding=[padh,padw],
#                              input_shape=[N,C,Hin,Win], filter_shape=[F,C,Hf,Wf])
  dW = fill(-2, Hout, Wout);

#  dX = conv2d_backward_data(W, dout, stride=[strideh,stridew], padding=[padh,padw],
#                            input_shape=[N,C,Hin,Win], filter_shape=[F,C,Hf,Wf])

  dX = fill(-2, Hout, Wout);

  # Partial derivatives for bias vector
  db = util.channel_sums(dout, F, Hout, Wout);
  #db = fill(-3, Hout, Wout);
  return dW, dX, db;
}


def init(F, C, Hf, Wf, seed) -> matrix<f64>, matrix<f64> {
  /*
   * Initialize the parameters of this layer.
   *
   * Note: This is just a convenience function, and parameters
   * may be initialized manually if needed.
   *
   * We use the heuristic by He et al., which limits the magnification
   * of inputs/gradients during forward/backward passes by scaling
   * unit-Gaussian weights by a factor of sqrt(2/n), under the
   * assumption of relu neurons.
   *  - http://arxiv.org/abs/1502.01852
   *
   * Inputs:
   *  - F: Number of filters.
   *  - C: Number of input channels (dimensionality of depth).
   *  - Hf: Filter height.
   *  - Wf: Filter width.
   *  - seed: The seed to initialize the weights
   *
   * Outputs:
   *  - W: Weights, of shape (F, C*Hf*Wf).
   *  - b: Biases, of shape (F, 1).
   */
  #W = rand(rows=F, cols=C*Hf*Wf, pdf="normal", seed=seed) * sqrt(2.0/(C*Hf*Wf))
  W = rand(F, C*Hf*Wf, 0.0, 256.0, 1.0, seed);
  b = fill(0.0, F, 1);
  return W, b;
}
