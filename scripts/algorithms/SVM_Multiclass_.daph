#-------------------------------------------------------------## Licensed to the Apache Software Foundation (ASF) under one# or more contributor license agreements.  See the NOTICE file# distributed with this work for additional information# regarding copyright ownership.  The ASF licenses this file# to you under the Apache License, Version 2.0 (the# "License"); you may not use this file except in compliance# with the License.  You may obtain a copy of the License at##   http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing,# software distributed under the License is distributed on an# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY# KIND, either express or implied.  See the License for the# specific language governing permissions and limitations# under the License.##-------------------------------------------------------------# This script has been manually translated from Apache SystemDS (https://github.com/apache/systemds).# Original file: scripts/builtin/msvm.dml# This script implements a multi-class Support Vector Machine (SVM)# with squared slack variables. The trained model comprises #classes# one-against-the-rest binary-class l2svm classification models.## INPUT:#-------------------------------------------------------------------------------# X              Feature matrix X (shape: m x n)# Y              Label vector y of class labels (shape: m x 1),#                where max(Y) is assumed to be the number of classes# intercept      Indicator if a bias column should be added to X and the model# epsilon        Tolerance for early termination if the reduction of objective#                function is less than epsilon times the initial objective# reg            Regularization parameter (lambda) for L2 regularization# maxIterations  Maximum number of conjugate gradient (outer l2svm) iterations# verbose        Indicator if training details should be printed# ------------------------------------------------------------------------------## OUTPUT:#-------------------------------------------------------------------------------# model          Trained model/weights (shape: n x max(Y), w/ intercept: n+1)#-------------------------------------------------------------------------------def msvm(X:matrix<f64>, Y:matrix<f64>, intercept:bool /*= false*/,    epsilon:double /*= 0.001*/, reg:double /*= 1.0*/, maxIterations:int /*= 100*/,    verbose:bool /*= false*/) -> matrix<f64>{  if( min(Y) < 0 )    stop("MSVM: Invalid Y input, containing negative values");    if(verbose)    print("Running Multiclass-SVM");  # Robustness for datasets with missing values (causing NaN gradients)  numNaNs = sum(isNan(X));  if(numNaNs > 0) {    print("msvm: matrix X contains "+numNaNs+" missing values, replacing with 0.");    X = replace(X, Double.NaN, 0.0);  }  # Append bias term if intercept is requested  if(intercept) {    ones = fill(1.0, nrow(X), 1);    X = cbind(X, ones);  }  if(ncol(Y) > 1)    Y = as.f64(idxMax(t(Y), 0));  # Assuming number of classes to be max contained in Y  numClasses = max(Y);  w = fill(0.0, ncol(X), numClasses);  # Loop over each class  for(class in 1:numClasses) {    # Extract the binary labels for the current class and convert to -1/+1    Y_local = 2 * (Y == class) - 1;        # Train the L2-SVM model for the current class    nnzY = sum(Y == class);    if(nnzY > 0) {      w[,class - 1] = l2svm(X, Y_local, false, epsilon, reg, maxIterations, verbose);    }    else {      w[,class - 1] = fill(-Infinity, ncol(X), 1);    }  }  return w;}